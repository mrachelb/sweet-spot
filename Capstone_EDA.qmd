---
title: "Capstone Project"
author: "Alex, Rachel, Vlatko, Malte"
date: "2024-06-06"
format: html
execute: 
  cache: true
  echo: false
  error: true
jupyter: python3
editor:
  render-on-save: true
---

# load libraries and data

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import datetime as dt

from sklearn.model_selection import TimeSeriesSplit
```


```{python}
%run functions.py
```

```{python}
pd.set_option("display.max_columns", None)
```

```{python}
d = pd.read_csv("data/daily_sales_report.csv")
school_h_be = pd.read_csv("data/hol_school_b.csv")
school_h_hh = pd.read_csv("data/hol_school_h.csv")
```


# EDA 

```{python}
d
```



## Converting "date" to datetime 

```{python}
d['date'] = pd.to_datetime(d['date'])
```



# Feature engeneering 

## Categorizing

```{python}

# Apply the function to create the 'item_category' column

d['item_category'] = d['item_name'].apply(categorize_item)
```


```{python}
d["item_category"].value_counts(normalize=True)
```


## Calculating total amount

```{python}
d['total_amount'] = d.apply(calculate_total_amount, axis=1)
```

```{python}
d
```


## Adding weather variables

```{python}
d = weather_data(d)
```

```{python}
d
```



## Balancing Item Categories


```{python}

updated_d = update_item_category(d)

```

```{python}
updated_d
```

```{python}
updated_d[updated_d["item_category"] == "other"]["item_name"].value_counts()
```


```{python}
updated_d["item_category"].value_counts()
```


```{python}
updated_d = updated_d[~updated_d["item_category"].isin(["other","not_donut"])]
```


```{python}
updated_d["item_category"].value_counts()
```


## Drop year and month features to avoid duplicates below

```{python}
updated_d = updated_d.drop(["year","month"], axis = 1)
```


## Adding holidays

```{python}
updated_d = hol_pub(updated_d)
```

```{python}
updated_d = hol_school(updated_d, school_h_be, school_h_hh)
```


## Adding date info

```{python}
updated_d = date_info(updated_d)
```


## Dropping duplicates

```{python}
updated_d = drop_duplicates(updated_d)
```



## Remove stores in Eppendorf, Schöneberg, Hauptbahnhof from dataset 

```{python}
updated_d = updated_d[(updated_d["date"] <= pd.to_datetime("2024-05-31")) &
           (-updated_d["store_name"].isin(["Eppendorf","Schöneberg","Hauptbahnhof"]))]
```


## Create "weekend" dummy

```{python}
updated_d["weekend"] = updated_d["weekday"].apply(lambda x: 1 if x in [5,6] else 0)
```


## Create "public_space" dummy

```{python}
updated_d["public_space"] = updated_d["store_name"].apply(lambda x: 1 if x in ["Potsdamer","Altona","KaDeWe","Hamburg Hauptbahnhof"] else 0)
```



## Create "box_deal" dummy


```{python}
updated_d["box_deal"] = updated_d["type_name"].apply(lambda x: 1 if x in "box" else 0)
```

```{python}
updated_d
```



## Time Series split

```{python}
updated_d = updated_d.set_index("date")
```

```{python}
days = np.sort(updated_d.index.unique())
days
```

```{python}
tscv = TimeSeriesSplit(n_splits=2, test_size = 7)
list(tscv.split(days))
```


```{python}
for train_index, test_index in tscv.split(days):
    train_days, test_days = days[train_index], days[test_index]
    train, test = updated_d.loc[train_days], updated_d.loc[test_days]

```



```{python}
train = train.reset_index()
test = test.reset_index()
```






# Creating .csv files

```{python}
updated_d.to_csv("data/cleaned_df.csv", index = False)

train.to_csv("data/train_df.csv", index=False)
test.to_csv("data/test_df.csv", index=False)
```